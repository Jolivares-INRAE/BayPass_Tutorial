---
title: "BayPass Pipeline"
author: "Jérôme OLIVARES & Mathieu GAUTIER"
date: "Septembre 2021"
output:
  html_document:
    toc: yes
    toc_depth: '2'
    df_print: paged
  github_document:
    fig_width: 15
    fig_height: 10
    dev: jpeg
  pdf_document:
    toc: yes
    toc_depth: '2'
editor_options:
  chunk_output_type: inline
---

#Prérequis:
L’utilisateur devra avoir une connaissance basique du logiciel Rstudio et être capable d’écrire et lancer des scripts sur un cluster de calcul. Les commandes décrites dans ce document ont été rédigées sous Rstudio version 1.4.1106 couplé à R 64 bits version 4.0.5. avec tous les packages nécessaires à jour.
Les lignes de commandes et scripts sous Linux ont été développés dans l’environnement bash et SLURM du cluster de calcul de la plateforme GenoToul de bioinformatique (GenoToul Bioinfo). Dans le cas d’une utilisation dans un autre environnement logiciel, l’utilisateur devra probablement effectuer des adaptations du code.
La dernière version du logiciel BayPass sera téléchargée depuis l’adresse http://www1.montpellier.inra.fr/CBGP/software/baypass/download.html et décompressée dans un répertoire local par l’utilisateur.
Le terme de chromosome sera utilisé en références aux appellations de contigs, scaffold, ou chromosomes qui correspondent aux séquences nucléotidiques du génome de référence, plus ou moins mature, qui sera utilisé.
##installation des packages
L'utilisation de ce pipeline nécessite l'installation au préalable des packages ci-dessous, il appartient à l'utilisateur de les installer sur son système.

install.packages(c("poolfstat"))  
install.packages(c("RColorBrewer"))  
install.packages(c("BiocManager"))  
BiocManager::install("mixOmics")  
install.packages(c("mvtnorm"))  
install.packages(c("geigen"))  
install.packages(c("corrplot"))  
install.packages(c("ape"))  
install.packages(c("VennDiagram"))  
install.packages(c("gridExtra"))  
install.packages(c("nVennR"))  
install.packages(c("tidyverse"))  

##chargement des librairies
```{r load-Packages, message=FALSE, warning=FALSE}
library(poolfstat)
library(RColorBrewer)
library(mixOmics)
library(mvtnorm)
library(geigen)
library(corrplot)
library(ape)
library(VennDiagram)
library(gridExtra)
library(nVennR)
library(tidyverse)
```
##Définition d'un espace de travail
Chaque utilisateur définira une arborescence de travail avec plusieurs dossiers contenant respectivement les fichiers vcf, les entrées BayPass, les sorties BayPass, les sorties POD et enfin un dossier recueillant les différents résultats (plots, liste de SNP...)
```{r work-space}
path_vcf <- "C:/BayPass_pipeline/vcf/"
path_input <- "C:/BayPass_pipeline/Input/13pops/chr1"
path_out <- "C:/BayPass_pipeline/Output/"
path_POD <- "C:/BayPass_pipeline/POD/13pops/chr1/"
path_res <- "C:/BayPass_pipeline/Resultats/13pops/chr1/"
```
##Obtention d'un fichier VCF
L'analyse qualité et l'alignement sur le génome de référence devront avoir été réalisé au préalable afin d'obtenir un fichier BAM correctement indéxé.
L’utilisation des Samtools et de Varscan est recommandé pour le variant calling, avec les paramètres de base, sauf la p-value qui est montée à 0.5 pour être le moins stringent possible. 
Un exemple de script est disponible à l'adresse suivante:
https://github.com/Jolivares-INRAE/Download/tree/BayPass_pipeline

IMPORTANT : 
Les chromosomes sexuels ayant une évolution historique différente des autosomes il conviendra, lorsque cela est possible, de les analyser à part.

#conversion du fichier VCF en objet pooldata
Lister le nom des populations dans le même ordre que celui du fichier .vcf dans un objet "pnames".
Lister les tailles haploïdes de chaque population (2x nbr individus pour les diploïdes) dans un objet "psizes"
Le fichier doit être ".vcf" ou compressé au format gzip ".vcf.gz"
min.rc =  minimum de reads qu'un allèle doit avoir (dans tous les pools) pour être retenu 
min.cov.per.pool = minimum de reads autorisées par pool pour que SNP soit retenu.
max.cov.per.pool = maximum de reads autorisées par pool pour que SNP soit retenu.
min.maf = fréquence allélique minimale (sur tous les pools) pour qu'un SNP soit retenu
```{r conversion-pooldata}
#Infos sur les pops
pnames <- as.character(c('13-1-S', '18-84-001-S', '17-47-003-S', '17-49-001-S', '85-3-4-S', 'IT-ID3-S', '17-47-002-R', '17-53-006-R', '30-1-R', '44-1-R', '44-2-R', '44-3-R', 'IT-ID1-R'))
psizes_A <- as.numeric(c('150', '180', '24', '114', '180', '44','180', '160', '200', '74', '80', '52', '72')) #ploydie autosome/chr2-28
psizes_Z <- as.numeric(c('150', '180', '24', '114', '180', '44','180', '160', '200', '74', '80', '52', '72')) #ploydie Z/chr1
psizes_W <- as.numeric(c('150', '180', '24', '114', '180', '44','180', '160', '200', '74', '80', '52', '72')) #ploydie W/chr29
#conversion du .vcf
GWAS.pooldata <- vcf2pooldata(vcf.file = paste(path_vcf, "Pool13pops_chr1-varscan.vcf", sep=""), poolsizes = psizes, poolnames = pnames, min.cov.per.pool = 4, min.rc = 2, max.cov.per.pool = 1e+06, min.maf = 0.01, remove.indels = FALSE, nlines.per.readblock = 1e+06)
```
#Analyses préliminaires
A partir de cet objet pooldata on faire une première analyse des Fst.
Des outils sont décrits et exemplifiés dans la vignette de PoolFstat : (https://cran.r-project.org/web/packages/poolfstat/vignettes/vignette.pdf)
On peut analyser ces Fst entre les populations deux à deux (pairwise) afin de déterminer et visualiser les différentiations génétiques entre populations.
On peut aussi calculer et plotter des Fst multi-locus en balayant le génome avec une fenêtre glissante de SNP consécutifs, une région génomique très différenciée apparaitra sous la forme d'une éruption de points colorés.

##Calcul et heatmap des Fst entre population (pairwise):
```{r heatmap-PW-fst, fig.width=10, fig.height=10}
#Calcul des pairwise Fst 
PairWise.fst <- compute.pairwiseFST(GWAS.pooldata, method = "Anova", min.cov.per.pool = 4, max.cov.per.pool = 1e+06, min.maf = 0.01, output.snp.values = FALSE)
#conversion en matrice de distance
df <- as.matrix(dist(t(PairWise.fst@PairwiseFSTmatrix)))
#heatmap
cim_color <- colorRampPalette(rev(brewer.pal(9, "Reds")))(25)
cim(df, color = cim_color, symkey = FALSE, margins = c(10, 10), title = "Genome wide Pairwise FST heatmap between populations")
```
##Calcul et plot des Fst en fenêtre glissante:
```{r plot-sliding-Fst, fig.width=20, fig.height=10}
#calcul des Fst avec une fenêtre glissante de 10 SNP ("sliding.window.size")
Multi.Loc.fst <- computeFST(GWAS.pooldata, method = "Anova", sliding.window.size = 100)
#conversion en objet data frame
df.fst<-as.data.frame(Multi.Loc.fst$sliding.windows.fst, h=T)
#plot en ligne. (le seuil indique la Fst globale estimée à l'échelle du génome).
Fst.plot = ggplot(data=df.fst, aes(x=CumulatedPosition/1e6, y=MultiLocusFst)) + geom_point(aes(color=Chr), alpha=0.8, size=1.5)
Fst.plot + scale_x_continuous() + scale_y_continuous() + theme(axis.title.x=element_blank(), axis.text.x=element_blank(), axis.ticks.x=element_blank()) + geom_hline(yintercept=Multi.Loc.fst$FST,lty=2) +  facet_grid(~Chr, scales = 'free_x', space = 'free_x', switch = 'x')
#facet_wrap(~Chr, scales = 'free_x', strip.position =c("bottom"))
```
#Conversion du pooldata en fichiers d'entrées pour BayPass
```{r Input-BayPass}
pooldata2genobaypass(GWAS.pooldata, writing.dir = path_input, subsamplesize = -1, subsamplingmethod = "thinning")
```
On récupère un fichier genobaypass qui contient les données brutes de génotypage, un fichier snpdet qui contient la liste des positions correspondantes et un fichier poolsize, qui est une copie de l'objet psizes.

#Design de l’analyse BayPass
Deux fichiers de paramétrages au format texte/tabulation doivent être créés :
Le premier fichier ecotype.txt identifie les covariables écologiques de chaque population, avec une covariable par ligne et autant de lignes que nécessaire. Seules sont acceptées les valeurs numériques de préférence en gradient (taille, poids, température...), les valeurs texte devront être converties, par exemple des noms de villes pourront être remplacées par une latitude ou une longitude. L’exemple suivant donne la structure d’un fichier pour 3 covariables (latitude/longitude/année) et 5 populations :

4.75	0.53	0.27	-0.86	-0.61
43.90	44.37	44.29	47.36	47.86
2019	2017	2017	2017	2018

Le deuxième fichier contraste.txt identifie l’appartenance de chaque population à un groupe référence (-1), un groupe test (1) ou aucun des deux groupes (0). Une ligne par combinaison de contraste. L’exemple suivant donne la structure d’un fichier pour 3 analyses de contraste : 

1	1	-1	-1	-1
1	0	 0	-1	-1
0	1	-1	-1	 0

1ere ligne = pop 1 et 2 VS pop 3, 4 et 5
2e ligne = pop 1 VS pop 4 et 5
3e ligne = pop 2 VS pop 3 et 4.

Ces fichiers seront aussi transférés sur le cluster de calcul.

IMPORTANT : Les analyses BayPass sont relativement longues (plusieurs heures) il est très fortement conseillé de multiplier les analyses de contraste ou de covariables en ajoutant autant de lignes que nécessaires dans ces fichiers de paramétrages plutôt que de relancer une analyse complète pour chacune d’entre elles. 

#Copie, subdivision des données et temps de calculs
Copier les fichiers genobaypass, snpdet, poolsize et les fichiers contraste.txt et ecotype.txt sur le cluster de calcul. Afin d’éviter d’éventuels problèmes de format les fichiers .txt sont passé à la commande dos2unix
La découpe en sous jeux de données des fichier genobaypass et snpdet se fait sous Bash avec la commande sed.
Exemple pour 100 sous jeux:

for i in {1..100}; do sed -n "$i~100p" genobaypass > genobaypass.sub$i; done
for i in {1..100}; do sed -n "$i~100p" snpdet > snpdet.sub$i; done

IMPORTANT: pour 25 000 SNP et 12 populations, une analyse (1contraste, 3 covariables) avec 1 CPU dure environ 8H, si on augmente le nombre de contraste à 8, le temps de calcul passe à environ 10H ce qui est nettement plus rentable que de relancer 8 fois l’analyse.
Si on alloue 8 CPU, l’analyse est 5 fois plus rapide mais pas 8 donc une partie (30 à 40%) du temps total CPU est perdue. A noter que la consommation de mémoire vive est négligeable, il n’y a pas de gain à espérer à allouer des gigaoctets de mémoire.

La stratégie la plus rentable est donc d’inclure dans une même analyse un maximum de combinaison de contraste/covariables, de découper en sous jeux de données de 25 000 à 50 000 SNP et d’allouer 1 CPU à chacun. Il n’est pas aberrant de faire un test sur une fraction des données totale et d’extrapoler pour avoir une idée du coût en temps et en ressources. 

#Baypass : l’analyse poolseq
La commande est la même pour les différents modèles employés par BayPass, ce sont les fichiers optionnels qui définissent le modèle : pas de fichiers pour le core model, l'option -efile pour le covariate model et l'option poolsize pour activer le mode Pool-Seq.
Un exemple de script d'analyse de type Pool-Seq, parallélisée sur 25 CPU est disponible à l'adresse suivante:
https://github.com/Jolivares-INRAE/Download/tree/BayPass_pipeline

Il est recommandé dans le cadre d’une analyse Pool-Seq d’utiliser et fixer le paramètre -d0yij à 1/5e de la valeur la plus faible du poolsize. (voir page 22 et 39 du manuel de BayPass).
Tous les fichiers de résultats cibleront le dossier dans lequel se trouve le script.

#Regroupement et validation des résultats
Chaque sous jeux de données analysés va produire 8 fichiers de résultats avec des extensions différentes, un premier contrôle visuel utile est de vérifier que tous les fichiers partageant la même extension soient de taille identique en kilo ou méga-octets. Des différences manifestes sont signes de problèmes lors de l'analyse (crash, disque plein…) conduisant à des fichiers incomplets.

Avant de regrouper les résultats, il faut valider l'homogénéité des analyses en comparant les matrices Ω entre elles par un indice de distance FMD, plus l'indice sera faible plus les matrices donc les analyses seront comparables.
```{r validation-matrice-omega, fig.width=10, fig.height=10}
source("C:/BayPass_pipeline/utils/baypass_utils.R")
prefix <- "GWAS-13pops-chr1_C8.sub"
#liste et compte les matrices Ω du répertoire "path"
listMatrix <- list.files(path_out, pattern="mat_omega.out")
nMatrix<-length(listMatrix)
cat("Nbr matrix files =", nMatrix, "\n")

#boucle sur toutes les matrices, calcule les distances FMD en pairwise et stocke le résultat
ListFMD<-c()
for (i in 1:nMatrix) for (j in 1:nMatrix) if(i!=j) {
omegaA=as.matrix(read.table(paste(path_out, prefix, i,"_mat_omega.out", sep="")))
omegaB=as.matrix(read.table(paste(path_out, prefix, j,"_mat_omega.out", sep="")))
FMD <- fmd.dist(omegaA, omegaB)
ListFMD <- c(ListFMD,FMD)
}
#calcule la moyenne et la sd de toutes les distances FMD
cat("FMD mean =", mean(ListFMD), "\n")
cat("FMD sd =" , sd(ListFMD), "\n")

#heatmap de la dernière matrice Ω.
colnames(omegaB) <-c(pnames)
rownames(omegaB) <-c(pnames)
cor.mat=cov2cor(omegaB)
cim_color <- colorRampPalette(rev(brewer.pal(9, "Blues")))(16)
cim(cor.mat, color = cim_color, symkey = FALSE, margins = c(10, 10), title = "Correlation map based on last "~hat(Omega))
```
Si les réplicats sont homogènes on merge les résultats xtx, C2, Betai pour tous les répliquats, un exemple de script est disponible à l'adresse suivante:
https://github.com/Jolivares-INRAE/Download/tree/BayPass_pipeline

Si l'analyse a été découpée en plusieurs chromosome on peut concaténer simplement en créant un nouveau fichier complet avec entêtes à partir du chr1, puis on concatène à la suite les autres fichiers sans l'entête:
cat Poolseq-chr1.Results.sorted > Poolseq-complet.results 
cat Poolseq-chr2.Results.sorted |  grep -v "MRK" - >> Poolseq-complet.results 
cat Poolseq-chr3.Results.sorted |  grep -v "MRK" - >> Poolseq-complet.results 
etc...

#Evaluation de la distribution des p.values des XtX
Cette évaluation se fait sur les p.values du fichier "XtX.merged.sorted":
```{r Distribution-XtX}
source("C:/BayPass_pipeline/utils/baypass_utils.R")
xtx.sorted=read.table(paste(path_out,"GWAS-13pops-chr1_C8.xtx.merged.sorted", sep=""),h=T)
hist(10**(-1*xtx.sorted$XtX_log10.1.pval.),freq=F,breaks=50)
abline(h=1)
```
Une explication de comment interpréter cet histogramme de distribution est disponible à l'adresse:
http://varianceexplained.org/statistics/interpreting-pvalue-histogram/
Si cette distribution n’est pas normale il est souhaitable de calibrer nos statistiques avec un jeu de données simulées.

#Création d'un jeu de données simulées "POD"
La fonction geno2YN convertit les données de comptages brutes en « Pseudo-Observed Data » (POD) et la fonction simulate.baypass génère un jeu de données simulées à partir de la matrice Ω déjà calculée (omegaB) ainsi qu'un constante Pi.beta que l'on récupère dans un des fichiers de sorties.
```{r POD data}
source("C:/BayPass_pipeline/utils/baypass_utils.R")
POD.data=geno2YN(paste(path_input, "genobaypass", sep=""))
pi.betaK=read.table(paste(path_out, "Poolseq.sub3_summary_beta_params.out", sep=""),h=T)$Mean
POD_BayPass<-simulate.baypass(omega.mat=omegaB,nsnp = 5000, beta.coef = NA, beta.pi = pi.betaK, sample.size=POD.data$NN, pi.maf=0, suffix="Poolseq.POD" )
```
Les 4 fichiers .POD générés (dans le dossier actif du pipeline) sont à copier sur le cluster de calcul. Le fichier G.Poolseq.POD sera analysé de la même manière que le jeu de données initial si ce n’est qu’il n’est pas nécessaire de découper ni de paralléliser l'analyse, le reste des paramètres (contraste, ecotype…) doit être identique.
#Analyse des résultats POD:
Les fichiers résultats POD_mat_omega, POD_summary_pi_xtx.out, sont copiés tel quel en local, le fichier POD_summary_contrast.out s’il contient les résultats de plusieurs contrastes doit être subdivisé par contraste (et renommés en ..POD_1..; ..POD2.. Etc…) au préalable pour obtenir une sortie par combinaison C2 qui seront aussi copiées en local.
```{r Thresholds}
source("C:/BayPass_pipeline/utils/baypass_utils.R")
POD.omega=as.matrix(read.table(paste(path_POD, "GWAS-13pops-chr1.POD_mat_omega.out", sep="")))
plot(POD.omega,omegaB) ; abline(a=0,b=1)
FMD.POD <- fmd.dist(POD.omega,omegaB)
cat("Distance FMD =", FMD.POD, "\n")
#Seuil XtX top 1%
POD.XtX=read.table(paste(path_POD, "GWAS-13pops-chr1.POD_summary_pi_xtx.out", sep=""),h=T)$M_XtX
thresh.XtX=quantile(POD.XtX,probs=0.99)
cat("Seuil XtX =", thresh.XtX, "(Max=", max(POD.XtX) ,")", "\n")
#Seuil C2 top 1%, pour chaque combinaison de contraste (3 dans l'exemple)
List.tresh.C2<-c()
for (j in 1:8) {
POD.C2.j=read.table(paste(path_POD, "GWAS-13pops-chr1.POD_C2_",j,".out", sep=""),h=T)$M_C2
thresh.C2.j=quantile(POD.C2.j,probs=0.99)
cat("Seuil C2-Contrast", j," =", thresh.C2.j, "(Max=", max(POD.C2.j) ,")", "\n")
List.tresh.C2<-c(List.tresh.C2,as.vector(thresh.C2.j))#récupère une liste des seuils
}
```
La matrice Ω POD est comparée à la matrice Ω initialement calculée (omegaB) afin de valider la similarité des analyses. La fonction quantile calcule le seuil en fonction de la valeur probs qu’on lui donne : probs = 0,99 pour un seuil à 1%, probs=0,999 pour un seuil à 0,1% etc. Enfin on affiche un plot de la corrélation entre les deux matrice Ω, le seuil calculé pour la statistique XtX et pour toutes les combinaisons de contraste C2. Le calcul d'un seuil pour le les Bayes Factors n'est pas pertinent.

#Analyses des résultats
L'analyse est faite avec les seuils calculés précédemment, si ce calcul n'a pas été fait il faudra définir ces seuil "manuellement".
```{r Fusion-&-plot, fig.width=10, fig.height=10}

BF.res.Cov1=read.table(paste(path_out, "13pops-chr1_STD_Betai.Cov1", sep=""),h=T)

thresh.BF<-c(15)

Manplot.B = ggplot(data=BF.res.Cov1, aes(x=BF.dB., y=eBPis)) +
  geom_point(aes(color=chr), alpha=0.8, size=1.5)+ scale_x_continuous() + scale_y_continuous()
Manplot.B + geom_hline(yintercept=quantile(BF.res.Cov1$Beta_is, probs=0.99))+
  geom_hline(yintercept=quantile(BF.res.Cov1$eBPis, probs=0.99))+
  geom_vline(xintercept=quantile(BF.res.Cov1$BF.dB., probs=0.99), color="blue")+
  geom_vline(xintercept=15, color="green")+
  facet_grid(~chr,scales = 'free_x', space = 'free_x', switch = 'x')

Manplot.A = ggplot(data=BF.res.Cov1, aes(x=pos, y=BF.dB.)) + geom_point(color="grey", alpha=0.8, size=0.5)+
  geom_point(data=subset(BF.res.Cov1, BF.res.Cov1$Beta_is >= quantile(BF.res.Cov1$Beta_is, probs=0.99)|BF.res.Cov1$Beta_is <= quantile(BF.res.Cov1$Beta_is, probs=0.01)), color="blue", alpha=0.8, size=1.5)+
  geom_point(data=subset(BF.res.Cov1, BF.res.Cov1$BF.dB.>=15), color="yellow", alpha=0.8, size=1)+
  geom_point(data=subset(BF.res.Cov1, BF.res.Cov1$BF.dB.>=15 & pos>53530000 & pos<53540000), color="black", alpha=0.8, size=1.5)+
  geom_point(data=subset(BF.res.Cov1, BF.res.Cov1$BF.dB.>=15 & pos>53580000 & pos<53600000), color="red", alpha=0.8, size=1.5)+
  geom_point(data=subset(BF.res.Cov1, BF.res.Cov1$BF.dB.>=15 & pos>53605000 & pos<53615000), color="green", alpha=0.8, size=1.5)
Manplot.A + scale_x_continuous() + scale_y_continuous() + geom_hline(yintercept=quantile(BF.res.Cov1$BF.dB., probs=0.99))+ 
facet_grid(~chr,scales = 'free_x', space = 'free_x', switch = 'x')

Manplot.C = ggplot(data=BF.res.Cov1, aes(x=eBPis, y=Beta_is)) + geom_point(color="blue", alpha=0.8, size=0.5)+ geom_point(data=subset(BF.res.Cov1, BF.res.Cov1$BF.dB.>15), color="red", alpha=0.8, size=1.5)
Manplot.C + scale_x_continuous() + scale_y_continuous() + geom_hline(yintercept=quantile(BF.res.Cov1$Beta_is, probs=0.99))+ geom_hline(yintercept=quantile(BF.res.Cov1$Beta_is, probs=0.01))+ geom_vline(xintercept=quantile(BF.res.Cov1$eBPis, probs=0.99))+ facet_grid(~chr,scales = 'free_x', space = 'free_x', switch = 'x')

Manplot.D = ggplot(data=BF.res.Cov1, aes(x=Beta_is, y=BF.dB.)) + geom_point(color="blue", alpha=0.8, size=0.5)+ geom_point(data=subset(BF.res.Cov1, BF.res.Cov1$BF.dB.>15 & BF.res.Cov1$Beta_is >= quantile(BF.res.Cov1$Beta_is, probs=0.99) | BF.res.Cov1$BF.dB.>15 & BF.res.Cov1$Beta_is <= quantile(BF.res.Cov1$Beta_is, probs=0.01)), color="red", alpha=0.8, size=1.5)
Manplot.D + scale_x_continuous() + scale_y_continuous() +
  geom_hline(yintercept=15)+
  # geom_vline(xintercept=quantile(BF.res.Cov1$Beta_is, probs=0.01))+
  # geom_vline(xintercept=quantile(BF.res.Cov1$Beta_is, probs=0.99))+
  facet_grid(~chr,scales = 'free_x', space = 'free_x', switch = 'x')


```
Le premier graphique est un Manhattan plot des valeurs de C2 le long des chromosomes disposés en lignes (facet_grid). Pour une disposition en grille il faudra utiliser l'option "facet_wrap": facet_wrap(~chr,scales = 'free_x', strip.position =c("bottom")).
Toutes les combinaisons sont possible (XtX/C2, C2/BF...) selon l'information que l'on souhaite en tirer.
Le deuxième graphique est un Manhattan plot selon 2 conditions: toutes les positions pour lesquelles le XtX et le BF sont supérieurs aux seuils définis
Enfin on peut exporter dans un fichier les données qui ont servies à établir le deuxième graphique.

#Comparaison par diagramme de Venn:
```{r venn, fig.width=20, fig.height=10}
Pops13_M<-read.table(paste0(path_out, "13pops_cov-M-chr1-28_Top1.txt"),h=T)
Pops13_V<-read.table(paste0(path_out, "13pops_cov-V-chr1-28_Top1.txt"),h=T)
Pops13_R<-read.table(paste0(path_out, "13pops_cov-R-chr1-28_Top1.txt"),h=T)


Manplot.MV = ggplot(NULL, aes(x=pos, y=BF.dB.)) + geom_point(data=Pops13_M, color="blue", alpha=0.8, size=0.5)+ geom_point(data=Pops13_V, color="red", alpha=0.8, size=0.5)+ ggtitle("Bleu = M Rouge =V")
Manplot.MV + scale_x_continuous() + scale_y_continuous() +
  geom_hline(yintercept=15)+
   facet_wrap(~chr,scales = 'free_x', strip.position =c("bottom"))

Manplot.MV = ggplot(NULL, aes(x=pos, y=BF.dB.)) + geom_point(data=subset(Pops13_M, BF.dB.>= 15), color="blue", alpha=0.8, size=0.5)+ geom_point(data=subset(Pops13_V, BF.dB.>= 15), color="red", alpha=0.8, size=0.5)+ ggtitle("Bleu = M Rouge =V")
Manplot.MV + scale_x_continuous() + scale_y_continuous() +
  geom_hline(yintercept=15)+
   facet_wrap(~chr,scales = 'free_x', strip.position =c("bottom"))

#Filtrage selon conditions
Datmp1 = subset(Pops13_M, BF.dB.>= 15)
Datmp2 = subset(Pops13_V, BF.dB.>= 15)
Datmp3 = subset(Pops13_R, BF.dB.>= 15)
Datmp4 = subset(Pops13_M, BF.dB.>= 15 & chr=="chr1")
Datmp5 = subset(Pops13_V, BF.dB.>= 15 & chr=="chr1")
#Conversion en liste au format "chr1_pos1, chr1_pos2, chr1_pos3, ...", 
List.SNP1<-paste(Datmp1[,1], "_", Datmp1[,2], sep="")
List.SNP2<-paste(Datmp2[,1], "_", Datmp2[,2], sep="")
List.SNP3<-paste(Datmp3[,1], "_", Datmp3[,2], sep="")
List.SNP4<-paste(Pops13_M[,1], "_", Pops13_M[,2], sep="")
List.SNP5<-paste(Pops13_V[,1], "_", Pops13_V[,2], sep="")
List.SNP6<-paste(Pops13_R[,1], "_", Pops13_R[,2], sep="")
List.SNP7<-cbind(paste(Datmp1[,1], "_", Datmp1[,2], sep=""),Datmp1[,28])# M avec BF
List.SNP8<-cbind(paste(Datmp2[,1], "_", Datmp2[,2], sep=""),Datmp2[,28])# V avec BF

List.SNP9<-paste(Datmp4[,1], "_", Datmp4[,2], sep="")
List.SNP10<-paste(Datmp5[,1], "_", Datmp5[,2], sep="")

#Diagramme de Venn
vd <- venn.diagram(x=list("M-BF15" = List.SNP7[,1], "V-BF15" = List.SNP8[,1], "R-BF15" = List.SNP1), fill = brewer.pal(3, "Set3"), cat.cex = 1.5, fontface = "bold", filename = NULL, main = "Intersect BF>=15 chr 1-28 ")
grid.newpage()
grid.draw(vd)

vd2 <- venn.diagram(x=list("M-BF15" = List.SNP1, "V-BF15" = List.SNP2, " " = List.SNP1), fill = brewer.pal(3, "Set3"), cat.cex = 1.5, fontface = "bold", filename = NULL, main = "Intersect BF>=15 chr 1-28 ")
grid.newpage()
grid.draw(vd2)

vd1 <- venn.diagram(x=list("M-chr1" = List.SNP9, "V-chr1" = List.SNP10, " " = List.SNP9), fill = brewer.pal(3, "Set3"), cat.cex = 1.5, fontface = "bold", filename = NULL, main = "Intersect BF15 chr 1 ")
grid.newpage()
grid.draw(vd1)
```

#Extraire les listes de chaque intersecte du diagramme:
```{r List-Venn}
myV <- plotVenn(list("M-BF15" = List.SNP1, "V-BF15" = List.SNP2))
myV <- plyr::ldply(listVennRegions(myV), cbind)
#write.table(myV, file=paste(path_res, "All_overlap.txt", sep=""), quote = FALSE, sep = "\t", row.names = FALSE)
#récupère la liste des intersectes
myV %>% distinct(myV[,1])
```
#Convertir les liste de SNP dans un intersecte en fichier bed
```{r Bed-Venn, fig.width=20, fig.height=10}
#subset en fonction de l'intersecte que l'on veut
tmp<-subset(myV,myV[,1] == "0, 1 (V-BF15)")
V.tmp<-separate(plyr::ldply(paste(tmp[,2]), cbind), col = "1",  sep = "_", into = c("chr", "pos"))
V.bed <- plyr::ldply(paste(V.tmp[,1], as.numeric(V.tmp[,2])-1, V.tmp[,2]), cbind)
V.bed<-mutate(separate(V.bed, col = "1",  sep = " ", into = c("chr", "start", "end")))
Unique_V<-V.bed
write.table(test, file=paste(path_out, "test.txt", sep=""), quote = FALSE, sep = "\t", row.names = FALSE)

#Extraction des BF pour plot
test<-  Overlap_MV %>%
  mutate_at(c("end"), as.integer)%>%
  rename(pos=end) %>%
  select(chr,pos)%>%
  left_join(Datmp1, by=c("chr","pos"))

Manplot.Ov = ggplot(test, aes(x=pos, y=BF.dB.)) + geom_point(color="blue", alpha=0.8, size=1)+ ggtitle("Overlap M / V = 95 snp")
Manplot.Ov + scale_x_continuous() + scale_y_continuous() +
  facet_wrap(~chr,scales = 'free_x', strip.position =c("bottom"))

testM<-  Unique_M %>%
  mutate_at(c("end"), as.integer)%>%
  rename(pos=end) %>%
  select(chr,pos)%>%
  left_join(Datmp1, by=c("chr","pos"))

Manplot.M = ggplot(testM, aes(x=pos, y=BF.dB.)) + geom_point(color="blue", alpha=0.8, size=1)+ ggtitle("Unique M / V = 95 snp")
Manplot.M + scale_x_continuous() + scale_y_continuous() +
  facet_wrap(~chr,scales = 'free_x', strip.position =c("bottom"))

testV<-  Unique_V %>%
  mutate_at(c("end"), as.integer)%>%
  rename(pos=end) %>%
  select(chr,pos)%>%
  left_join(Datmp2, by=c("chr","pos"))

Manplot.V = ggplot(testV, aes(x=pos, y=BF.dB.)) + geom_point(color="blue", alpha=0.8, size=1)+ ggtitle("Unique M / V = 95 snp")
Manplot.V + scale_x_continuous() + scale_y_continuous() +
  facet_wrap(~chr,scales = 'free_x', strip.position =c("bottom"))

Manplot.MV2 = ggplot(NULL, aes(x=pos, y=BF.dB.)) + geom_point(data=testM, color="blue", alpha=0.8, size=1)+ geom_point(data=test, color="red", alpha=0.8, size=1.5)+ geom_point(data=testV, color="green", alpha=0.8, size=0.8)+ ggtitle("Bleu = M Rouge =V")
Manplot.MV2 + scale_x_continuous() + scale_y_continuous() +
  geom_hline(yintercept=15)+
   facet_wrap(~chr,scales = 'free_x', strip.position =c("bottom"))

Slide_Over<-read.table(paste0(path_out, "overlap_MV.sliding"),h=T)
Slide_M<-read.table(paste0(path_out, "Unique_M.sliding"),h=T)
Slide_V<-read.table(paste0(path_out, "Unique_V.sliding"),h=T)

Man.slide = ggplot(NULL, aes(x=Start, y=BF)) + geom_point(data=Slide_M, color="blue", alpha=0.8, size=1)+ geom_point(data=Slide_Over, color="red", alpha=0.8, size=1.5)+ geom_point(data=Slide_V, color="green", alpha=0.8, size=0.8)+ ggtitle("Bleu = M Rouge =Overlap, Vert =V")
Man.slide + scale_x_continuous() + scale_y_continuous() + facet_wrap(~chr,scales = 'free_x', strip.position =c("bottom"))
Man.slide = ggplot(NULL, aes(x=Start, y=BF)) + geom_point(data=Slide_M, color="blue", alpha=0.8, size=1)+ geom_point(data=Slide_Over, color="red", alpha=0.8, size=1.5)+ geom_point(data=Slide_V, color="green", alpha=0.8, size=0.8)+ ggtitle("Bleu = M Rouge =Overlap, Vert =V")
Man.slide + scale_x_continuous() + scale_y_continuous() + facet_grid(~chr,scales = 'free_x', space = 'free_x', switch = 'x')

```

