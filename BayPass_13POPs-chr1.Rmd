---
title: "BayPass Pipeline"
author: "Jérôme OLIVARES & Mathieu GAUTIER"
date: "Septembre 2021"
output:
  html_document:
    toc: yes
    toc_depth: '2'
    df_print: paged
  github_document:
    fig_width: 15
    fig_height: 10
    dev: jpeg
  pdf_document:
    toc: yes
    toc_depth: '2'
editor_options:
  chunk_output_type: inline
---

#Prérequis:
L’utilisateur devra avoir une connaissance basique du logiciel Rstudio et être capable d’écrire et lancer des scripts sur un cluster de calcul. Les commandes décrites dans ce document ont été rédigées sous Rstudio version 1.4.1106 couplé à R 64 bits version 4.0.5. avec tous les packages nécessaires à jour.
Les lignes de commandes et scripts sous Linux ont été développés dans l’environnement bash et SLURM du cluster de calcul de la plateforme GenoToul de bioinformatique (GenoToul Bioinfo). Dans le cas d’une utilisation dans un autre environnement logiciel, l’utilisateur devra probablement effectuer des adaptations du code.
La dernière version du logiciel BayPass sera téléchargée depuis l’adresse http://www1.montpellier.inra.fr/CBGP/software/baypass/download.html et décompressée dans un répertoire local par l’utilisateur.
Le terme de chromosome sera utilisé en références aux appellations de contigs, scaffold, ou chromosomes qui correspondent aux séquences nucléotidiques du génome de référence, plus ou moins mature, qui sera utilisé.
##installation des packages
L'utilisation de ce pipeline nécessite l'installation au préalable des packages ci-dessous, il appartient à l'utilisateur de les installer sur son système.

install.packages(c("poolfstat"))  
install.packages(c("RColorBrewer"))  
install.packages(c("BiocManager"))  
BiocManager::install("mixOmics")  
install.packages(c("mvtnorm"))  
install.packages(c("geigen"))  
install.packages(c("corrplot"))  
install.packages(c("ape"))  
install.packages(c("VennDiagram"))  
install.packages(c("gridExtra"))  
install.packages(c("nVennR"))  
install.packages(c("tidyverse"))  

##chargement des librairies
```{r load-Packages, message=FALSE, warning=FALSE}
library(poolfstat)
library(RColorBrewer)
library(mixOmics)
library(mvtnorm)
library(geigen)
library(corrplot)
library(ape)
library(VennDiagram)
library(gridExtra)
library(nVennR)
library(tidyverse)
```
##Définition d'un espace de travail
Chaque utilisateur définira une arborescence de travail avec plusieurs dossiers contenant respectivement les fichiers vcf, les entrées BayPass, les sorties BayPass, les sorties POD et enfin un dossier recueillant les différents résultats (plots, liste de SNP...)
```{r work-space}
path_vcf <- "C:/BayPass_pipeline/vcf/"
path_input <- "C:/BayPass_pipeline/Input/13pops/chr1/"
path_out <- "C:/BayPass_pipeline/Output/13pops/chr1/"
path_POD <- "C:/BayPass_pipeline/POD/13pops/"
path_res <- "C:/BayPass_pipeline/Resultats/13pops/chr1/"
```
##Obtention d'un fichier VCF
L'analyse qualité et l'alignement sur le génome de référence devront avoir été réalisé au préalable afin d'obtenir un fichier BAM correctement indéxé.
L’utilisation des Samtools et de Varscan est recommandé pour le variant calling, avec les paramètres de base, sauf la p-value qui est montée à 0.5 pour être le moins stringent possible. 
Un exemple de script est disponible à l'adresse suivante:
https://github.com/Jolivares-INRAE/Download/tree/BayPass_pipeline

IMPORTANT : 
Les chromosomes sexuels ayant une évolution historique différente des autosomes il conviendra, lorsque cela est possible, de les analyser à part.

#conversion du fichier VCF en objet pooldata
Lister le nom des populations dans le même ordre que celui du fichier .vcf dans un objet "pnames".
Lister les tailles haploïdes de chaque population (2x nbr individus pour les diploïdes) dans un objet "psizes"
Le fichier doit être ".vcf" ou compressé au format gzip ".vcf.gz"
min.rc =  minimum de reads qu'un allèle doit avoir (dans tous les pools) pour être retenu 
min.cov.per.pool = minimum de reads autorisées par pool pour que SNP soit retenu.
max.cov.per.pool = maximum de reads autorisées par pool pour que SNP soit retenu.
min.maf = fréquence allélique minimale (sur tous les pools) pour qu'un SNP soit retenu
```{r conversion-pooldata}
#Infos sur les pops
pnames <- as.character(c('13-1-S', '18-84-001-S', '17-47-003-S', '17-49-001-S', '85-3-4-S', 'IT-ID3-S', '17-47-002-R', '17-53-006-R', '30-1-R', '44-1-R', '44-2-R', '44-3-R', 'IT-ID1-R'))
#psizes_A <- as.numeric(c('150', '180', '24', '114', '180', '44','180', '160', '200', '74', '80', '52', '72')) #ploydie autosome/chr2-28
psizes_Z <- as.numeric(c('120', '135', '16', '86', '135', '30','135', '120', '150', '60', '63', '42', '53')) #ploydie Z/chr1
#psizes_W <- as.numeric(c('30', '45', '8', '28', '45', '14','45', '40', '50', '14', '17', '10', '19')) #ploydie W/chr29
#conversion du .vcf
GWAS.pooldata <- vcf2pooldata(vcf.file = paste(path_vcf, "Wilde_13pops_chr1-varscan.vcf.gz", sep=""), poolsizes = psizes_Z, poolnames = pnames, min.cov.per.pool = 4, min.rc = 2, max.cov.per.pool = 1e+06, min.maf = 0.05, remove.indels = FALSE, nlines.per.readblock = 1e+06)
#conversion d'un .sync (PoPoolation)
#GWAS.pooldata <- popsync2pooldata(sync.file = paste(path_vcf, "13pops_chr1.sync.gz", sep=""), poolsizes = psizes_W, poolnames = pnames, min.cov.per.pool = 4, min.rc = 2, max.cov.per.pool = 1e+06, min.maf = 0.05, noindel = FALSE, nlines.per.readblock = 1e+06, nthreads = 8)
#élimine le 1% supérieur considéré comme trop fortement couvert (région très dupliquée, biais de séquençage...)
GWAS.pooldata<-pooldata.subset(GWAS.pooldata, cov.qthres.per.pool = c(0,0.99))
```
#Analyses préliminaires
A partir de cet objet pooldata on faire une première analyse des Fst.
Des outils sont décrits et exemplifiés dans la vignette de PoolFstat : (https://cran.r-project.org/web/packages/poolfstat/vignettes/vignette.pdf)
On peut analyser ces Fst entre les populations deux à deux (pairwise) afin de déterminer et visualiser les différentiations génétiques entre populations.
On peut aussi calculer et plotter des Fst multi-locus en balayant le génome avec une fenêtre glissante de SNP consécutifs, une région génomique très différenciée apparaitra sous la forme d'une éruption de points colorés.

##Calcul et heatmap des Fst entre population (pairwise):
```{r heatmap-PW-fst, fig.width=10, fig.height=10}
#Calcul des pairwise Fst 
PairWise.fst <- compute.pairwiseFST(GWAS.pooldata, method = "Anova", min.cov.per.pool = 4, max.cov.per.pool = 1e+06, min.maf = 0.01, output.snp.values = FALSE)
#conversion en matrice de distance
df <- as.matrix(dist(t(PairWise.fst@PairwiseFSTmatrix)))
#heatmap
cim_color <- colorRampPalette(rev(brewer.pal(9, "Reds")))(25)
cim(df, color = cim_color, symkey = FALSE, margins = c(10, 10), title = "Genome wide Pairwise FST heatmap between populations")
```
##Calcul et plot des Fst en fenêtre glissante:
```{r plot-sliding-Fst, fig.width=20, fig.height=10}
#calcul des Fst avec une fenêtre glissante de 10 SNP ("sliding.window.size")
Multi.Loc.fst <- computeFST(GWAS.pooldata, method = "Anova", sliding.window.size = 100)
#conversion en objet data frame
df.fst<-as.data.frame(Multi.Loc.fst$sliding.windows.fst, h=T)
#plot en ligne. (le seuil indique la Fst globale estimée à l'échelle du génome).
Fst.plot = ggplot(data=df.fst, aes(x=CumulatedPosition/1e6, y=MultiLocusFst)) + geom_point(aes(color=Chr), alpha=0.8, size=1.5)
Fst.plot + scale_x_continuous() + scale_y_continuous() + theme(axis.title.x=element_blank(), axis.text.x=element_blank(), axis.ticks.x=element_blank()) + geom_hline(yintercept=Multi.Loc.fst$FST,lty=2) +  facet_grid(~Chr, scales = 'free_x', space = 'free_x', switch = 'x')
#facet_wrap(~Chr, scales = 'free_x', strip.position =c("bottom"))
```
#Conversion du pooldata en fichiers d'entrées pour BayPass
```{r Input-BayPass}
pooldata2genobaypass(GWAS.pooldata, writing.dir = path_input, subsamplesize = -1, subsamplingmethod = "thinning")
```
On récupère un fichier genobaypass qui contient les données brutes de génotypage, un fichier snpdet qui contient la liste des positions correspondantes et un fichier poolsize, qui est une copie de l'objet psizes.

#Design de l’analyse BayPass
Deux fichiers de paramétrages au format texte/tabulation doivent être créés :
Le premier fichier ecotype.txt identifie les covariables écologiques de chaque population, avec une covariable par ligne et autant de lignes que nécessaire. Seules sont acceptées les valeurs numériques de préférence en gradient (taille, poids, température...), les valeurs texte devront être converties, par exemple des noms de villes pourront être remplacées par une latitude ou une longitude. L’exemple suivant donne la structure d’un fichier pour 3 covariables (latitude/longitude/année) et 5 populations :

4.75	0.53	0.27	-0.86	-0.61
43.90	44.37	44.29	47.36	47.86
2019	2017	2017	2017	2018

Le deuxième fichier contraste.txt identifie l’appartenance de chaque population à un groupe référence (-1), un groupe test (1) ou aucun des deux groupes (0). Une ligne par combinaison de contraste. L’exemple suivant donne la structure d’un fichier pour 3 analyses de contraste : 

1	1	-1	-1	-1
1	0	 0	-1	-1
0	1	-1	-1	 0

1ere ligne = pop 1 et 2 VS pop 3, 4 et 5
2e ligne = pop 1 VS pop 4 et 5
3e ligne = pop 2 VS pop 3 et 4.

Ces fichiers seront aussi transférés sur le cluster de calcul.

IMPORTANT : Les analyses BayPass sont relativement longues (plusieurs heures) il est très fortement conseillé de multiplier les analyses de contraste ou de covariables en ajoutant autant de lignes que nécessaires dans ces fichiers de paramétrages plutôt que de relancer une analyse complète pour chacune d’entre elles. 

#Copie, subdivision des données et temps de calculs
Copier les fichiers genobaypass, snpdet, poolsize et les fichiers contraste.txt et ecotype.txt sur le cluster de calcul. Afin d’éviter d’éventuels problèmes de format les fichiers .txt sont passé à la commande dos2unix
La découpe en sous jeux de données des fichier genobaypass et snpdet se fait sous Bash avec la commande sed.
Exemple pour 100 sous jeux:

for i in {1..100}; do sed -n "$i~100p" genobaypass > genobaypass.sub$i; done
for i in {1..100}; do sed -n "$i~100p" snpdet > snpdet.sub$i; done

IMPORTANT: pour 25 000 SNP et 12 populations, une analyse (1contraste, 3 covariables) avec 1 CPU dure environ 8H, si on augmente le nombre de contraste à 8, le temps de calcul passe à environ 10H ce qui est nettement plus rentable que de relancer 8 fois l’analyse.
Si on alloue 8 CPU, l’analyse est 5 fois plus rapide mais pas 8 donc une partie (30 à 40%) du temps total CPU est perdue. A noter que la consommation de mémoire vive est négligeable, il n’y a pas de gain à espérer à allouer des gigaoctets de mémoire.

La stratégie la plus rentable est donc d’inclure dans une même analyse un maximum de combinaison de contraste/covariables, de découper en sous jeux de données de 25 000 à 50 000 SNP et d’allouer 1 CPU à chacun. Il n’est pas aberrant de faire un test sur une fraction des données totale et d’extrapoler pour avoir une idée du coût en temps et en ressources. 

#Baypass : l’analyse poolseq
La commande est la même pour les différents modèles employés par BayPass, ce sont les fichiers optionnels qui définissent le modèle : pas de fichiers pour le core model, l'option -efile pour le covariate model et l'option poolsize pour activer le mode Pool-Seq.
Un exemple de script d'analyse de type Pool-Seq, parallélisée sur 25 CPU est disponible à l'adresse suivante:
https://github.com/Jolivares-INRAE/Download/tree/BayPass_pipeline

Il est recommandé dans le cadre d’une analyse Pool-Seq d’utiliser et fixer le paramètre -d0yij à 1/5e de la valeur la plus faible du poolsize. (voir page 22 et 39 du manuel de BayPass).
Tous les fichiers de résultats cibleront le dossier dans lequel se trouve le script.

#Regroupement et validation des résultats
Chaque sous jeux de données analysés va produire 8 fichiers de résultats avec des extensions différentes, un premier contrôle visuel utile est de vérifier que tous les fichiers partageant la même extension soient de taille identique en kilo ou méga-octets. Des différences manifestes sont signes de problèmes lors de l'analyse (crash, disque plein…) conduisant à des fichiers incomplets.

Avant de regrouper les résultats, il faut valider l'homogénéité des analyses en comparant les matrices Ω entre elles par un indice de distance FMD, plus l'indice sera faible plus les matrices donc les analyses seront comparables.
```{r validation-matrice-omega, fig.width=10, fig.height=10}
source("C:/BayPass_pipeline/utils/baypass_utils.R")
prefix <- "13pops-chr1_STD-2000.sub"
#liste et compte les matrices Ω du répertoire "path"
listMatrix <- list.files(path_out, pattern="mat_omega.out")
nMatrix<-length(listMatrix)
cat("Nbr matrix files =", nMatrix, "\n")

#boucle sur toutes les matrices, calcule les distances FMD en pairwise et stocke le résultat
ListFMD<-c()
for (i in 1:nMatrix) for (j in 1:nMatrix) if(i!=j) {
omegaA=as.matrix(read.table(paste(path_out, prefix, i,"_mat_omega.out", sep="")))
omegaB=as.matrix(read.table(paste(path_out, prefix, j,"_mat_omega.out", sep="")))
FMD <- fmd.dist(omegaA, omegaB)
ListFMD <- c(ListFMD,FMD)
}

#heatmap de la dernière matrice Ω.
colnames(omegaB) <-c(pnames)
rownames(omegaB) <-c(pnames)
cor.mat=cov2cor(omegaB)
cim_color <- colorRampPalette(rev(brewer.pal(9, "Blues")))(16)
cim(cor.mat, color = cim_color, symkey = FALSE, margins = c(10, 10), title = "Correlation map based on last "~hat(Omega))
#SVD de la dernière matrice Ω.
SVD_omega<-plot.omega(omega=omegaB, pop.names=pnames, main = expression("Singular Value Decomposition of last " * ~hat(Omega)), pos=3)
SVD_omega

#calcule la moyenne et la sd de toutes les distances FMD
cat("FMD mean =", mean(ListFMD), "\n")
cat("FMD sd =" , sd(ListFMD), "\n")
```
Si les réplicats sont homogènes on merge les résultats xtx, C2, Betai pour tous les répliquats, un exemple de script est disponible à l'adresse suivante:
https://github.com/Jolivares-INRAE/Download/tree/BayPass_pipeline

Si l'analyse a été découpée en plusieurs chromosome on peut concaténer simplement en créant un nouveau fichier complet avec entêtes à partir du chr1, puis on concatène à la suite les autres fichiers sans l'entête:
cat Poolseq-chr1.Results.sorted > Poolseq-complet.results 
cat Poolseq-chr2.Results.sorted |  grep -v "MRK" - >> Poolseq-complet.results 
cat Poolseq-chr3.Results.sorted |  grep -v "MRK" - >> Poolseq-complet.results 
etc...

#Evaluation de la distribution des p.values des XtX
Cette évaluation se fait sur les p.values du fichier "XtX.merged.sorted":
```{r Distribution-XtX}
source("C:/BayPass_pipeline/utils/baypass_utils.R")
xtx.sorted=read.table(paste(path_out,"13pops-chr1-Core.xtx.merged.sorted", sep=""),h=T)
hist(10**(-1*xtx.sorted$log10.1.pval.),freq=F,breaks=50)
abline(h=1)
```
Une explication de comment interpréter cet histogramme de distribution est disponible à l'adresse:
http://varianceexplained.org/statistics/interpreting-pvalue-histogram/
Si cette distribution n’est pas normale il est souhaitable de calibrer nos statistiques avec un jeu de données simulées.

#Création d'un jeu de données simulées "POD"
La fonction geno2YN convertit les données de comptages brutes en « Pseudo-Observed Data » (POD) et la fonction simulate.baypass génère un jeu de données simulées à partir de la matrice Ω déjà calculée (omegaB) ainsi qu'un constante Pi.beta que l'on récupère dans un des fichiers de sorties.
```{r POD data}
source("C:/BayPass_pipeline/utils/baypass_utils.R")
POD.data=geno2YN(paste(path_input, "genobaypass", sep=""))
pi.betaK=read.table(paste(path_out, "Poolseq.sub3_summary_beta_params.out", sep=""),h=T)$Mean
#POD_BayPass<-simulate.baypass(omega.mat=omegaB,nsnp = 5000, beta.coef = NA, beta.pi = pi.betaK, sample.size=POD.data$NN, pi.maf=0, suffix="Poolseq.POD" )
```
Les 4 fichiers .POD générés (dans le dossier actif du pipeline) sont à copier sur le cluster de calcul. Le fichier G.Poolseq.POD sera analysé de la même manière que le jeu de données initial si ce n’est qu’il n’est pas nécessaire de découper ni de paralléliser l'analyse, le reste des paramètres (contraste, ecotype…) doit être identique.
#Analyse des résultats POD:
Les fichiers résultats POD_mat_omega, POD_summary_pi_xtx.out, sont copiés tel quel en local, le fichier POD_summary_contrast.out s’il contient les résultats de plusieurs contrastes doit être subdivisé par contraste (et renommés en ..POD_1..; ..POD2.. Etc…) au préalable pour obtenir une sortie par combinaison C2 qui seront aussi copiées en local.
```{r Thresholds}
source("C:/BayPass_pipeline/utils/baypass_utils.R")
POD.omega=as.matrix(read.table(paste(path_POD, "GWAS-13pops-chr1.POD_mat_omega.out", sep="")))
plot(POD.omega,omegaB) ; abline(a=0,b=1)
FMD.POD <- fmd.dist(POD.omega,omegaB)
cat("Distance FMD =", FMD.POD, "\n")
#Seuil XtX top 1%
POD.XtX=read.table(paste(path_POD, "GWAS-13pops-chr1.POD_summary_pi_xtx.out", sep=""),h=T)$M_XtX
thresh.XtX=quantile(POD.XtX,probs=0.99)
cat("Seuil XtX =", thresh.XtX, "(Max=", max(POD.XtX) ,")", "\n")
#Seuil C2 top 1%, pour chaque combinaison de contraste (3 dans l'exemple)
List.tresh.C2<-c()
for (j in 1:8) {
POD.C2.j=read.table(paste(path_POD, "GWAS-13pops-chr1.POD_C2_",j,".out", sep=""),h=T)$M_C2
thresh.C2.j=quantile(POD.C2.j,probs=0.99)
cat("Seuil C2-Contrast", j," =", thresh.C2.j, "(Max=", max(POD.C2.j) ,")", "\n")
List.tresh.C2<-c(List.tresh.C2,as.vector(thresh.C2.j))#récupère une liste des seuils
}
```
La matrice Ω POD est comparée à la matrice Ω initialement calculée (omegaB) afin de valider la similarité des analyses. La fonction quantile calcule le seuil en fonction de la valeur probs qu’on lui donne : probs = 0,99 pour un seuil à 1%, probs=0,999 pour un seuil à 0,1% etc. Enfin on affiche un plot de la corrélation entre les deux matrice Ω, le seuil calculé pour la statistique XtX et pour toutes les combinaisons de contraste C2. Le calcul d'un seuil pour le les Bayes Factors n'est pas pertinent.

#Analyses des résultats
L'analyse est faite avec les seuils calculés précédemment, si ce calcul n'a pas été fait il faudra définir ces seuil "manuellement".
```{r Import}
XtX.res=read.table(paste(path_out, "13pops-chr1-Aux-5001.xtx", sep=""),h=T)
BF.res.Cov1=read.table(paste(path_out, "13pops-chr1.Aux-5001.Betai-Cov1", sep=""),h=T)
C2.res.C1=read.table(paste(path_out, "13pops_chr1_AuxM-5001.contrast-C1", sep=""),h=T)
#C2.res.C2=read.table(paste(path_out, "13pops_chr1_AuxM-Prior.contrast-C2", sep=""),h=T)

# Fusion des résultats XtX/C2-N°1/BF-N°1 par chr puis position

Joined.res1 = merge(x=XtX.res,y=merge(x=C2.res.C1,y=BF.res.Cov1, by=c("chr","pos")), by=c("chr","pos"))
#Joined.res2 = merge(x=XtX.res,y=merge(x=C2.res.C2,y=BF.res.Cov1, by=c("chr","pos")), by=c("chr","pos"))

#Définition des seuils ou copie des seuils POD

cat("Seuil 5% XtX =", quantile(XtX.res$M_XtX, probs=0.95), "(Max=", max(XtX.res$M_XtX) ,")", "\n")
cat("Seuil 1% XtX =", quantile(XtX.res$M_XtX, probs=0.99), "(Max=", max(XtX.res$M_XtX) ,")", "\n")
cat("Seuil 5% C2-1 =", quantile(C2.res.C1$M_C2, probs=0.95), "(Max=", max(C2.res.C1$M_C2) ,")", "\n")
cat("Seuil 1% C2-1 =", quantile(C2.res.C1$M_C2, probs=0.99), "(Max=", max(C2.res.C1$M_C2) ,")", "\n")
cat("Seuil 5% BF-1 =", quantile(BF.res.Cov1$BF.dB., probs=0.95), "(Max=", max(BF.res.Cov1$BF.dB.) ,")", "\n")
cat("Seuil 1% BF-1 =", quantile(BF.res.Cov1$BF.dB., probs=0.99), "(Max=", max(BF.res.Cov1$BF.dB.) ,")", "\n")

```

```{r plot, fig.width=20, fig.height=10}

thresh.XtX=quantile(XtX.res$M_XtX, probs=0.99)
thresh.C2=quantile(C2.res.C1$M_C2, probs=0.99)
thresh.BF<-c(20)

Slide_Cov1=read.table(paste(path_out, "13pops-chr1-Aux-5001.Betai-Cov1.20Ksliding20", sep=""),h=T)
Slide_XtX=read.table(paste(path_out, "13pops-chr1-Aux-5001.xtx.20Ksliding21", sep=""),h=T)
Slide_C2=read.table(paste(path_out, "13pops_chr1_AuxM-5001.contrast-C1.20Ksliding3", sep=""),h=T)

#Manhattan plot simple des valeurs de XtX 
Manplot.resXtX = ggplot(data=Joined.res1, aes(x=pos, y=M_XtX)) + geom_point(aes(color=chr), alpha=0.8, size=1.5) + ggtitle("position VerSus XtX (Seuil = top 1%)")
Manplot.resXtX + scale_x_continuous() + scale_y_continuous() + theme(axis.title.x=element_blank(), axis.text.x=element_blank(), axis.ticks.x=element_blank())+ geom_hline(yintercept=thresh.XtX)+ facet_grid(~chr,scales = 'free_x', space = 'free_x', switch = 'x')
#plot de la fenêtre glissante Aux Model XtX.
Manplot.Slide2 = ggplot(data=Slide_XtX, aes(x=Start, y=XtX)) + geom_point(aes(color=chr), alpha=0.8, size=1.5) + ggtitle("sliding 50K window versus XtX >15 AuxModel")
Manplot.Slide2 + scale_x_continuous() + scale_y_continuous() + theme(axis.title.x=element_blank(), axis.text.x=element_blank(), axis.ticks.x=element_blank())+ facet_grid(~chr,scales = 'free_x', space = 'free_x', switch = 'x')

#Manhattan plot simple des valeurs de contrastes C2
Manplot.resC1 = ggplot(data=Joined.res1, aes(x=pos, y=M_C2)) + geom_point(aes(color=chr), alpha=0.8, size=1.5) + ggtitle("position VerSus contrast1 (Seuil = top 1%)")
Manplot.resC1 + scale_x_continuous() + scale_y_continuous() + theme(axis.title.x=element_blank(), axis.text.x=element_blank(), axis.ticks.x=element_blank())+ geom_hline(yintercept=thresh.C2)+ facet_grid(~chr,scales = 'free_x', space = 'free_x', switch = 'x')
#plot de la fenêtre glissante Aux Model Contraste
Manplot.Slide3 = ggplot(data=Slide_C2, aes(x=Start, y=C2)) + geom_point(aes(color=chr), alpha=0.8, size=1.5) + ggtitle("sliding 50K window versus C2 >10 AuxModel")
Manplot.Slide3 + scale_x_continuous() + scale_y_continuous() + theme(axis.title.x=element_blank(), axis.text.x=element_blank(), axis.ticks.x=element_blank())+ facet_grid(~chr,scales = 'free_x', space = 'free_x', switch = 'x')

#plot des BF Aux Model
Manplot.resBF1 = ggplot(data=Joined.res1, aes(x=pos, y=BF.dB.)) + geom_point(aes(color=chr), alpha=0.8, size=1.5) + ggtitle("position versus BF1 (Seuil = 20)")
Manplot.resBF1 + scale_x_continuous() + scale_y_continuous() + theme(axis.title.x=element_blank(), axis.text.x=element_blank(), axis.ticks.x=element_blank())+ geom_hline(yintercept=thresh.BF)+ facet_grid(~chr,scales = 'free_x', space = 'free_x', switch = 'x')
#plot de la fenêtre glissante Aux Model BF.
Manplot.Slide1 = ggplot(data=Slide_Cov1, aes(x=Start, y=BF)) + geom_point(aes(color=chr), alpha=0.8, size=1.5) + ggtitle("sliding 50K window versus BF >20 AuxModel")
Manplot.Slide1 + scale_x_continuous() + scale_y_continuous() + theme(axis.title.x=element_blank(), axis.text.x=element_blank(), axis.ticks.x=element_blank())+ facet_grid(~chr,scales = 'free_x', space = 'free_x', switch = 'x')

#Manhattan plot sous 3 conditions: XtX>seuil & C2>seuil & BF>seuil
Manplot.thresh1 = ggplot(data=subset(Joined.res1, M_XtX>thresh.XtX & M_C2>thresh.C2 & BF.dB.>thresh.BF), aes(x=pos, y=BF.dB.)) + geom_point(aes(color=chr), alpha=0.8, size=1.5)+ ggtitle("position versus Top 1% XtX & top 1% C2 & BF1 > 20") 
Manplot.thresh1 + scale_x_continuous() + scale_y_continuous() + theme(axis.title.x=element_blank(), axis.text.x=element_blank(), axis.ticks.x=element_blank())+ facet_grid(~chr,scales = 'free_x', space = 'free_x', switch = 'x')

#write.table(Joined.res1, file=paste(path_res, "Chr1_XtX_BF_C2_maf005.txt", sep=""), quote = FALSE, sep = "\t", row.names = FALSE)
```
Le premier graphique est un Manhattan plot des valeurs de C2 le long des chromosomes disposés en lignes (facet_grid). Pour une disposition en grille il faudra utiliser l'option "facet_wrap": facet_wrap(~chr,scales = 'free_x', strip.position =c("bottom")).
Toutes les combinaisons sont possible (XtX/C2, C2/BF...) selon l'information que l'on souhaite en tirer.
Le deuxième graphique est un Manhattan plot selon 2 conditions: toutes les positions pour lesquelles le XtX et le BF sont supérieurs aux seuils définis
Enfin on peut exporter dans un fichier les données qui ont servies à établir le deuxième graphique.

#Comparaison par diagramme de Venn:
```{r Listes}
#Merge des résultats par chr et pos
#XtX_C2_Join1 = merge(x=XtX.res,y=C2.res.C1, by=c("chr","pos"))
#XtX_C2_Join2 = merge(x=XtX.res,y=C2.res.C2, by=c("chr","pos"))
#XtX_BF_Join1 = merge(x=XtX.res,y=BF.res.Cov1, by=c("chr","pos"))
#XtX_BF_Join2 = merge(x=XtX.res,y=BF.res.Cov2, by=c("chr","pos"))

#C2_BF_Join1 = merge(x=C2.res.C1,y=BF.res.Cov1, by=c("chr","pos"))
#C2_BF_Join2 = merge(x=C2.res.C1,y=BF.res.Cov2, by=c("chr","pos"))
#C2_BF_Join3 = merge(x=C2.res.C2,y=BF.res.Cov1, by=c("chr","pos"))
#C2_BF_Join4 = merge(x=C2.res.C2,y=BF.res.Cov2, by=c("chr","pos"))

#Filtrage selon conditions
thresh.BF2<-c(10)
Datmp1 = subset(Joined.res1, M_XtX> thresh.XtX )
Datmp2 = subset(Joined.res1, M_C2>thresh.C2)
Datmp3 = subset(Joined.res1, BF.dB.>thresh.BF2)
#Datmp4 = subset(XtX_BF_Join2, M_XtX> thresh.XtX & BF.dB.>thresh.BF2)
#Datmp5 = subset(C2_BF_Join1, M_C2>thresh.C2 & BF.dB.>thresh.BF2)
#Datmp6 = subset(C2_BF_Join2, M_C2>thresh.C2 & BF.dB.>thresh.BF2)
#Datmp7 = subset(C2_BF_Join3, M_C2>thresh.C2 & BF.dB.>thresh.BF2)
#Datmp8 = subset(C2_BF_Join4, M_C2>thresh.C2 & BF.dB.>thresh.BF2)
#Datmp9 = subset(BF.res.Cov1, BF.dB.>7.5)
#Datmp10 = subset(BF.res.Cov1, BF.dB.>15)
#Datmp11 = subset(BF.res.Cov2, BF.dB.>7.5)
#Datmp12 = subset(BF.res.Cov2, BF.dB.>15)

#Conversion en liste au format "chr1_pos1, chr1_pos2, chr1_pos3, ...", 
List.SNP1<-paste(Datmp1[,1], "_", Datmp1[,2], sep="")
List.SNP2<-paste(Datmp2[,1], "_", Datmp2[,2], sep="")
List.SNP3<-paste(Datmp3[,1], "_", Datmp3[,2], sep="")
#List.SNP4<-paste(Datmp4[,1], "_", Datmp4[,2], sep="")
#List.SNP5<-paste(Datmp5[,1], "_", Datmp5[,2], sep="")
#List.SNP6<-paste(Datmp6[,1], "_", Datmp6[,2], sep="")
#List.SNP7<-paste(Datmp7[,1], "_", Datmp7[,2], sep="")
#List.SNP8<-paste(Datmp8[,1], "_", Datmp8[,2], sep="")
#List.SNP9<-paste(Datmp9[,1], "_", Datmp9[,2], sep="") #BF1 7.5
#List.SNP10<-paste(Datmp10[,1], "_", Datmp10[,2], sep="") #BF1 15
#List.SNP11<-paste(Datmp11[,1], "_", Datmp11[,2], sep="") #BF2 7.5
#List.SNP12<-paste(Datmp12[,1], "_", Datmp12[,2], sep="") #BF2 15

```

```{r Export}
#Exporte les données filtrées sous conditions
#write.table(Manplot.thresh$data, row.names = FALSE, file=paste(path_res, "XtX-C2_VS_pos.txt", sep=""), quote = FALSE, sep = "\t")
#créé et exporte un fichier au format bed
list.tmp <- paste(Datmp3[,1], Datmp3[,2]-1, Datmp3[,2])
List.bed<-separate(plyr::ldply(list.tmp, cbind), col = "1",  sep = " ", into = c("chr", "start", "end"))
write.table(List.bed, row.names = FALSE, file=paste(path_res, "List_Outliers_BF10.bed", sep=""), quote = FALSE, sep = "\t")
```

```{r venn}
#Diagramme de Venn
#cat.col = c("darkgreen", "black", "darkblue")
vd0 <- venn.diagram(x=list("XtX top1%" = List.SNP1, "C2 top 1%" = List.SNP2, "BF >50" = List.SNP3), fill = c("blue", "green", "red"), cat.col = c("blue", "green", "red"), cat.cex = 1.5, fontface = "bold", filename = NULL)
#vd1 <- venn.diagram(x=list("XtX_C1" = List.SNP1, "XtX_C2" = List.SNP2), fill = c("blue", "green"), cat.col = c("blue", "green"), cat.cex = 1.5, fontface = "bold", filename = NULL)
#vd2 <- venn.diagram(x=list("XtX_BF1" = List.SNP3, "XtX_BF2" = List.SNP4, "." = List.SNP4), fill = brewer.pal(3, "Set3"), cat.cex = 1.5, fontface = "bold", filename = NULL)
##vd3 <- venn.diagram(x=list("C1_BF1" = List.SNP5, "C1_BF2" = List.SNP6, "." = List.SNP6), fill = brewer.pal(3, "Set3"), cat.cex = 1.5, fontface = "bold", filename = NULL)
#vd4 <- venn.diagram(x=list("C2_BF1" = List.SNP7, "C2_BF2" = List.SNP8, "." = List.SNP8), fill = brewer.pal(3, "Set3"), cat.cex = 1.5, fontface = "bold", filename = NULL)
grid.newpage()
grid.draw(vd0)

```

#Extraire les listes de chaque intersecte du diagramme:
```{r List-Venn}
myV <- plotVenn(list("XtX_BF1" = List.SNP3, "XtX_BF2" = List.SNP4))
myV <- plyr::ldply(listVennRegions(myV), cbind)
write.table(myV, file=paste(path_res, "Seed2001_Overlap_XtX_BF.txt", sep=""), quote = FALSE, sep = "\t", row.names = FALSE)
#récupère la liste des intersectes
myV %>% distinct(myV[,1])
```
#Convertir les liste de SNP dans un intersecte en fichier bed
```{r Bed-Venn}
#subset en fonction de l'intersecte que l'on veut
tmp<-subset(myV,myV[,1] == "1, 1, 1 (Contraste01, Contraste02, Contraste03)")
V.tmp<-separate(plyr::ldply(paste(tmp[,2]), cbind), col = "1",  sep = "_", into = c("chr", "pos"))
V.bed <- plyr::ldply(paste(V.tmp[,1], as.numeric(V.tmp[,2])-1, V.tmp[,2]), cbind)
V.bed<-mutate(separate(V.bed, col = "1",  sep = " ", into = c("chr", "start", "end")))
write.table(V.bed, file=paste(path_res, "overlap_3_contrastes.bed", sep=""), quote = FALSE, sep = "\t", row.names = FALSE)
```
#L'intersect se fait avec le BED contre un fichier GFF/GTF comme un transcriptome par exemple.

Très léger, ça passe en frontal:

module load bioinfo/bedtools-2.27.1
bedtools intersect -wb -a overlap.bed -b /home/midier/work/RNA_Reads/Merged/RNAseq_merged.gtf > overlap.intersect
#Même chose le GFF3 Gensas.
bedtools intersect -wb -a RY-3rep_overlap.bed -b Annotations_Gensas.gff3 > RY-3rep_Gensas.intersect


On obtient:
chr1    314013    314014    chr1    StringTie   transcript 314014
314014  1000    -   .   gene_id "MSTRG.34"; transcript_id "MSTRG.34.2";
chr1    576413    576414    chr1    StringTie   transcript 576414
576414  1000    +   .   gene_id "MSTRG.52"; transcript_id "MSTRG.52.1";
chr1    576413    576414    chr1    StringTie   transcript 576414
576414  1000    +   .   gene_id "MSTRG.53"; transcript_id "MSTRG.53.1";

# récupérer une liste des genes ID de la colonne 13 en gardant l'ordre initial (plus facile pour s'y retrouver)
#recupère la colonne 13 | enlèbve les " et ; | garde une seule valeur en cas de doublon (sans tri) > enregistre
awk '{print $13}' overlap.intersect | sed -e 's/"\|;//g' - | awk '!a[$0]++' -  > overlap.gene.list

# récupérer une liste des transcript ID de la colonne 15 en gardant l'ordre initial (plus facile pour s'y retrouver)
#recupère la colonne 15 | enlèbve les " et ; | garde une seule valeur en cas de doublon (sans tri) > enregistre
awk '{print $15}' overlap.intersect | sed -e 's/"\|;//g' - | awk '!a[$0]++' -  > overlap.transcript.list

# extraire les séquences correspondantes à cette liste depuis un fasta

module load bioinfo/seqtk-1.3
seqtk subseq ~/work/Pipe_RNAseq/Transcriptome_GTF/Merged/Cpom_Full_2021_transcripts.fasta cds.list > cds.fas
#Comparaison entre RUN
```{r}
seed2001.Cov1=read.table(paste("C:/BayPass_pipeline/Output/13pops/seed-2001-31274562/", "GWAS-13pops-chr1.Betai-Cov1.merged.sorted", sep=""),h=T)
seed2001.Cov2=read.table(paste("C:/BayPass_pipeline/Output/13pops/seed-2001-31274562/", "GWAS-13pops-chr1.Betai-Cov2.merged.sorted", sep=""),h=T)
seed5001.Cov1=read.table(paste("C:/BayPass_pipeline/Output/13pops/seed-5001-31250906/", "GWAS-13pops-chr1.Betai-Cov1.merged.sorted", sep=""),h=T)
seed5001.Cov2=read.table(paste("C:/BayPass_pipeline/Output/13pops/seed-5001-31250906/", "GWAS-13pops-chr1.Betai-Cov2.merged.sorted", sep=""),h=T)
seed8001.Cov1=read.table(paste("C:/BayPass_pipeline/Output/13pops/seed-8001-31430093/", "GWAS-13pops-chr1.Betai-Cov1.merged.sorted", sep=""),h=T)
seed8001.Cov2=read.table(paste("C:/BayPass_pipeline/Output/13pops/seed-8001-31430093/", "GWAS-13pops-chr1.Betai-Cov2.merged.sorted", sep=""),h=T)
Datmp13 = subset(seed2001.Cov1, BF.dB.>7.5)
Datmp14 = subset(seed2001.Cov1, BF.dB.>15)
Datmp15 = subset(seed2001.Cov2, BF.dB.>7.5)
Datmp16 = subset(seed2001.Cov2, BF.dB.>15)
Datmp17 = subset(seed5001.Cov1, BF.dB.>7.5)
Datmp18 = subset(seed5001.Cov1, BF.dB.>15)
Datmp19 = subset(seed5001.Cov2, BF.dB.>7.5)
Datmp20 = subset(seed5001.Cov2, BF.dB.>15)
Datmp21 = subset(seed8001.Cov1, BF.dB.>7.5)
Datmp22 = subset(seed8001.Cov1, BF.dB.>15)
Datmp23 = subset(seed8001.Cov2, BF.dB.>7.5)
Datmp24 = subset(seed8001.Cov2, BF.dB.>15)
Datmp25 = subset(C2_BF_Join1, M_C2>thresh.C2)
Datmp26 = subset(C2_BF_Join1, BF.dB.>15)
Datmp27 = subset(C2_BF_Join2, BF.dB.>15)
Datmp28 = subset(C2_BF_Join1, BF.dB.>7.5)
Datmp29 = subset(C2_BF_Join2, BF.dB.>7.5)


List.SNP13<-paste(Datmp13[,1], "_", Datmp13[,2], sep="") #2001-BF1 7.5
List.SNP14<-paste(Datmp14[,1], "_", Datmp14[,2], sep="") #2001-BF1 15
List.SNP15<-paste(Datmp13[,1], "_", Datmp15[,2], sep="") #2001-BF2 7.5
List.SNP16<-paste(Datmp14[,1], "_", Datmp16[,2], sep="") #2001-BF2 15
List.SNP17<-paste(Datmp17[,1], "_", Datmp17[,2], sep="") #5001-BF1 7.5
List.SNP18<-paste(Datmp18[,1], "_", Datmp18[,2], sep="") #5001-BF1 15
List.SNP19<-paste(Datmp19[,1], "_", Datmp19[,2], sep="") #5001-BF2 7.5
List.SNP20<-paste(Datmp20[,1], "_", Datmp20[,2], sep="") #5001-BF2 15
List.SNP21<-paste(Datmp21[,1], "_", Datmp21[,2], sep="") #8001-BF1 7.5
List.SNP22<-paste(Datmp22[,1], "_", Datmp22[,2], sep="") #8001-BF1 15
List.SNP23<-paste(Datmp23[,1], "_", Datmp23[,2], sep="") #8001-BF2 7.5
List.SNP24<-paste(Datmp24[,1], "_", Datmp24[,2], sep="") #8001-BF2 15
List.SNP25<-paste(Datmp25[,1], "_", Datmp25[,2], sep="") #C2 top5%
List.SNP26<-paste(Datmp26[,1], "_", Datmp26[,2], sep="") #BF1 > 15
List.SNP27<-paste(Datmp26[,1], "_", Datmp27[,2], sep="") #BF2 > 15
List.SNP28<-paste(Datmp28[,1], "_", Datmp28[,2], sep="") #BF1 > 7.5
List.SNP29<-paste(Datmp29[,1], "_", Datmp29[,2], sep="") #BF2 > 7.5
```

```{r venn}
#Diagramme de Venn
#cat.col = c("darkgreen", "black", "darkblue")
vd5 <- venn.diagram(x=list("2001-Cov1" = List.SNP14, "5001-Cov1" = List.SNP18, "8001-Cov1" = List.SNP22), fill = c("blue", "green", "orange"), cat.col = c("blue", "green", "orange"), cat.cex = 1.5, fontface = "bold", filename = NULL)
vd6 <- venn.diagram(x=list("2001-Cov2" = List.SNP16, "5001-Cov2" = List.SNP20, "8001-Cov2" = List.SNP24), fill = c("blue", "green", "orange"), cat.col = c("blue", "green", "orange"), cat.cex = 1.5, fontface = "bold", filename = NULL)
vd7 <- venn.diagram(x=list("2001-Cov2" = List.SNP15, "5001-Cov2" = List.SNP19, "8001-Cov2" = List.SNP23), fill = c("blue", "green", "orange"), cat.col = c("blue", "green", "orange"), cat.cex = 1.5, fontface = "bold", filename = NULL)
vd8 <- venn.diagram(x=list("2001-Cov1" = List.SNP13, "5001-Cov1" = List.SNP17, "8001-Cov1" = List.SNP21), fill = c("blue", "green", "orange"), cat.col = c("blue", "green", "orange"), cat.cex = 1.5, fontface = "bold", filename = NULL)
grid.newpage()
grid.draw(vd8)

```